<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Remembrances</title><link>https://madeindigio.github.io/remembrances-mcp/es/</link><description>Recent content on Remembrances</description><generator>Hugo</generator><language>es</language><lastBuildDate>Sat, 22 Nov 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://madeindigio.github.io/remembrances-mcp/es/index.xml" rel="self" type="application/rss+xml"/><item><title>Release 1.4.6: Mejoras de Estabilidad y Fiabilidad</title><link>https://madeindigio.github.io/remembrances-mcp/es/blog/2025/release-1.4.6/</link><pubDate>Sat, 22 Nov 2025 00:00:00 +0000</pubDate><guid>https://madeindigio.github.io/remembrances-mcp/es/blog/2025/release-1.4.6/</guid><description>&lt;p>Nos complace anunciar &lt;strong>Remembrances MCP 1.4.6&lt;/strong>, una versiÃ³n de mantenimiento enfocada en mejoras de estabilidad y fiabilidad basadas en los valiosos comentarios de nuestra comunidad desde el lanzamiento de la versiÃ³n 1.0.0.&lt;/p>
&lt;h2 id="quÃ©-se-ha-corregido">QuÃ© Se Ha Corregido&lt;/h2>
&lt;h3 id="-mejor-gestiÃ³n-de-memoria">ðŸ”§ Mejor GestiÃ³n de Memoria&lt;/h3>
&lt;p>Hemos solucionado varios problemas relacionados con el procesamiento y almacenamiento de memorias:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Mejor procesamiento por lotes&lt;/strong> â€“ Corregido un problema donde el procesamiento de grandes lotes de embeddings podÃ­a fallar bajo ciertas condiciones. El sistema ahora gestiona la memoria de forma mÃ¡s eficiente cuando trabaja con muchos documentos a la vez.&lt;/p></description></item><item><title>Release 1.0.0: Memoria IA Verdaderamente Local</title><link>https://madeindigio.github.io/remembrances-mcp/es/blog/2025/release-1.0.0/</link><pubDate>Tue, 18 Nov 2025 00:00:00 +0000</pubDate><guid>https://madeindigio.github.io/remembrances-mcp/es/blog/2025/release-1.0.0/</guid><description>&lt;p>Â¡Estamos encantados de anunciar el lanzamiento de &lt;strong>Remembrances MCP 1.0.0&lt;/strong> â€“ un hito importante que cumple nuestra promesa de memoria IA verdaderamente local!&lt;/p>
&lt;h2 id="novedades">Novedades&lt;/h2>
&lt;h3 id="-soporte-nativo-para-modelos-gguf">ðŸ§  Soporte Nativo para Modelos GGUF&lt;/h3>
&lt;p>La caracterÃ­stica principal de esta versiÃ³n es el &lt;strong>soporte integrado para modelos de embeddings GGUF&lt;/strong>. Ya no necesitas ejecutar Ollama ni depender de APIs externas compatibles con OpenAI para generar embeddings. Simplemente descarga un modelo GGUF de Hugging Face y apunta Remembrances MCP hacia Ã©l:&lt;/p></description></item></channel></rss>