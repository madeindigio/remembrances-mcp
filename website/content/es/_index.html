---
title: "Remembrances MCP"
---

{{< blocks/cover title="Remembrances MCP" image_anchor="top" height="full" color="primary" >}}
<div class="mx-auto">
  <p class="lead mt-5">Memoria a largo plazo para agentes IA con embeddings locales que priorizan la privacidad</p>
  <a class="btn btn-lg btn-primary mr-3 mb-4" href="{{< relref "/docs" >}}">
    Comenzar <i class="fas fa-arrow-alt-circle-right ml-2"></i>
  </a>
  <a class="btn btn-lg btn-secondary mr-3 mb-4" href="https://github.com/madeindigio/remembrances-mcp">
    Ver en GitHub <i class="fab fa-github ml-2 "></i>
  </a>
  <p class="lead mt-5">ðŸ”’ Privacidad primero â€¢ âš¡ AceleraciÃ³n GPU â€¢ ðŸ’° Sin costes â€¢ ðŸŽ¯ Flexible</p>
</div>
{{< /blocks/cover >}}

{{% blocks/lead color="white" %}}
Remembrances MCP es un servidor MCP basado en Go que proporciona **capacidades de memoria a largo plazo** para agentes IA.

Soporta mÃºltiples capas de memoria (clave-valor, vector/RAG, base de datos de grafos) usando **SurrealDB**, y puede gestionar bases de conocimiento mediante archivos Markdown.

**NUEVO**: Â¡Ahora con modelos de embeddings GGUF locales para privacidad completa y aceleraciÃ³n GPU!
{{% /blocks/lead %}}

{{< blocks/section color="dark" >}}
{{% blocks/feature icon="fa-lock" title="Privacidad Primero" %}}
Todos los embeddings se generan localmente con modelos GGUF. Sin envÃ­o de datos externos.
{{% /blocks/feature %}}

{{% blocks/feature icon="fa-bolt" title="AceleraciÃ³n GPU" %}}
Soporte para Metal (macOS), CUDA (NVIDIA) y ROCm (AMD) para un rendimiento ultrarrÃ¡pido.
{{% /blocks/feature %}}

{{% blocks/feature icon="fa-dollar-sign" title="Sin Costes" %}}
Sin costes de API para generaciÃ³n de embeddings. Ejecuta todo localmente.
{{% /blocks/feature %}}

{{% blocks/feature icon="fa-database" title="MÃºltiples Capas de Almacenamiento" %}}
Soporte para clave-valor, vector/RAG y base de datos de grafos con SurrealDB.
{{% /blocks/feature %}}

{{% blocks/feature icon="fa-file-alt" title="GestiÃ³n de Base de Conocimiento" %}}
Gestiona bases de conocimiento con simples archivos Markdown.
{{% /blocks/feature %}}

{{% blocks/feature icon="fa-plug" title="IntegraciÃ³n Flexible" %}}
Soporte para Ollama, API de OpenAI y modelos GGUF locales.
{{% /blocks/feature %}}

{{< /blocks/section >}}

{{< blocks/section color="white" >}}
<div class="col-12">
<h2 class="text-center">Inicio RÃ¡pido</h2>
<p class="text-center">Comienza con Remembrances MCP en minutos</p>
</div>

<div class="col-lg-4">
<h3>1. Descargar Modelo</h3>
<p>Descarga un modelo de embeddings GGUF desde Hugging Face:</p>
<pre><code>wget https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF/resolve/main/nomic-embed-text-v1.5.Q4_K_M.gguf</code></pre>
</div>

<div class="col-lg-4">
<h3>2. Compilar y Ejecutar</h3>
<p>Compila el proyecto e inicia el servidor:</p>
<pre><code>make build
./run-remembrances.sh \
  --gguf-model-path ./nomic-embed-text-v1.5.Q4_K_M.gguf \
  --gguf-gpu-layers 32</code></pre>
</div>

<div class="col-lg-4">
<h3>3. Conecta tu Agente</h3>
<p>Configura tu agente IA para usar el servidor MCP:</p>
<pre><code>{
  "mcpServers": {
    "remembrances": {
      "command": "./remembrances-mcp",
      "args": ["--gguf-model-path", "model.gguf"]
    }
  }
}</code></pre>
</div>

{{< /blocks/section >}}

{{< blocks/section color="primary" >}}
<div class="col-12 text-center">
<h2>Â¿Listo para comenzar?</h2>
<a class="btn btn-lg btn-secondary mr-3 mb-4" href="{{< relref "/docs" >}}">
  Leer la DocumentaciÃ³n <i class="fas fa-arrow-alt-circle-right ml-2"></i>
</a>
</div>
{{< /blocks/section >}}
