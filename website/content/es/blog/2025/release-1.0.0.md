---
title: "Release 1.0.0: Memoria IA Verdaderamente Local"
linkTitle: Release 1.0.0
date: 2025-11-18
author: Equipo Remembrances MCP
description: >
  Â¡Anunciamos Remembrances MCP 1.0.0 con soporte nativo para modelos GGUF y SurrealDB embebido - sin dependencias externas!
tags: [release, anuncio]
---

Â¡Estamos encantados de anunciar el lanzamiento de **Remembrances MCP 1.0.0** â€“ un hito importante que cumple nuestra promesa de memoria IA verdaderamente local!

## Novedades

### ðŸ§  Soporte Nativo para Modelos GGUF

La caracterÃ­stica principal de esta versiÃ³n es el **soporte integrado para modelos de embeddings GGUF**. Ya no necesitas ejecutar Ollama ni depender de APIs externas compatibles con OpenAI para generar embeddings. Simplemente descarga un modelo GGUF de Hugging Face y apunta Remembrances MCP hacia Ã©l:

```bash
./remembrances-mcp --gguf-model-path ./nomic-embed-text-v1.5.Q4_K_M.gguf
```

Esto significa:
- **Cero dependencias externas** para la generaciÃ³n de embeddings
- **Privacidad completa** â€“ tus datos nunca salen de tu mÃ¡quina
- **Despliegue simplificado** â€“ Â¡un binario, un archivo de modelo, listo!

### ðŸ’¾ Base de Datos SurrealDB Embebida

Junto con el soporte GGUF, hemos integrado una **base de datos SurrealDB embebida** directamente en el binario. Ya no necesitas instalar, configurar ni gestionar un servidor de base de datos separado:

```bash
./remembrances-mcp --db-path ./mis-memorias.db --gguf-model-path ./model.gguf
```

Tus memorias ahora se almacenan en un Ãºnico archivo de base de datos portÃ¡til que puedes respaldar fÃ¡cilmente o mover entre sistemas.

### âš¡ AceleraciÃ³n GPU

Para quienes buscan el mÃ¡ximo rendimiento, hemos aÃ±adido soporte de aceleraciÃ³n GPU:
- **Metal** para macOS (Apple Silicon)
- **CUDA** para GPUs NVIDIA
- **ROCm** para GPUs AMD

Activa la aceleraciÃ³n GPU con un simple flag:

```bash
./remembrances-mcp --gguf-model-path ./model.gguf --gguf-gpu-layers 32
```

### ðŸ”„ Compatibilidad Hacia AtrÃ¡s

No te preocupes â€“ Â¡todas tus configuraciones existentes siguen funcionando! Remembrances MCP 1.0.0 mantiene soporte completo para:

- **APIs de embeddings compatibles con OpenAI** â€“ Usa OpenAI, Azure OpenAI, o cualquier servicio compatible
- **Ollama** â€“ ContinÃºa usando tu instalaciÃ³n local de Ollama si lo prefieres
- **SurrealDB externo** â€“ ConÃ©ctate a instancias de SurrealDB remotas o auto-alojadas para despliegues distribuidos

## Por QuÃ© Esto Importa

Con la versiÃ³n 1.0.0, Remembrances MCP se convierte en una **soluciÃ³n de memoria IA verdaderamente autocontenida**. Ya sea que estÃ©s construyendo un asistente IA personal, una aplicaciÃ³n enfocada en la privacidad, o simplemente quieras experimentar con memoria IA sin dependencias en la nube, ahora tienes todo lo que necesitas en un Ãºnico binario.

## CÃ³mo Empezar

1. Descarga la Ãºltima versiÃ³n desde [GitHub Releases](https://github.com/madeindigio/remembrances-mcp/releases/tag/v1.0.0)
2. Descarga un modelo de embeddings GGUF (recomendamos [nomic-embed-text-v1.5](https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF))
3. Ejecuta:
   ```bash
   ./remembrances-mcp --gguf-model-path ./nomic-embed-text-v1.5.Q4_K_M.gguf
   ```

Consulta nuestra [documentaciÃ³n](/docs/) para instrucciones detalladas de configuraciÃ³n y opciones.

## Gracias

Â¡Un enorme agradecimiento a todos los que contribuyeron a esta versiÃ³n a travÃ©s de comentarios, reportes de errores y solicitudes de funcionalidades. Esto es solo el comienzo â€“ Â¡tenemos planes emocionantes para el futuro de Remembrances MCP!

---

*Â¿Tienes preguntas o comentarios? Â¡Abre un issue en [GitHub](https://github.com/madeindigio/remembrances-mcp/issues) o inicia una discusiÃ³n!*